#!/usr/bin/env python3
"""
æµ‹è¯•æ¸…ç†åçš„çˆ¬è™«åŠŸèƒ½
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.crawler.image_crawler import ImageCrawler

def test_clean_crawler():
    """æµ‹è¯•æ¸…ç†åçš„çˆ¬è™«åŠŸèƒ½"""
    print("ğŸ§¹ æµ‹è¯•æ¸…ç†åçš„å›¾ç‰‡çˆ¬è™«")
    print("=" * 60)
    
    # åˆå§‹åŒ–çˆ¬è™«
    crawler = ImageCrawler()
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            'movie': 'é’¢é“ä¾ ',
            'actor': 'å°ç½—ä¼¯ç‰¹Â·å”å°¼',
            'expected_query': 'é’¢é“ä¾  å°ç½—ä¼¯ç‰¹Â·å”å°¼ å•äºº å‰§ç…§ é«˜æ¸… ä¸ªäºº ç‰¹å†™ ç‹¬ç…§ äººç‰©'
        },
        {
            'movie': 'å¤ä»‡è€…è”ç›Ÿ',
            'actor': 'å…‹é‡Œæ–¯Â·åŸƒæ–‡æ–¯',
            'expected_query': 'å¤ä»‡è€…è”ç›Ÿ å…‹é‡Œæ–¯Â·åŸƒæ–‡æ–¯ å•äºº å‰§ç…§ é«˜æ¸… ä¸ªäºº ç‰¹å†™ ç‹¬ç…§ äººç‰©'
        }
    ]
    
    print("ğŸ­ æµ‹è¯•ç™¾åº¦å•äººå‰§ç…§æœç´¢:")
    print("-" * 40)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. ç”µå½±: {test_case['movie']}")
        print(f"   æ¼”å‘˜: {test_case['actor']}")
        print(f"   å…³é”®è¯: {test_case['expected_query']}")
        
        try:
            urls = crawler.search_baidu_images(
                query=test_case['actor'],
                movie_title=test_case['movie'],
                max_results=5
            )
            
            if urls:
                print(f"   âœ… æ‰¾åˆ° {len(urls)} å¼ å•äººå‰§ç…§")
                print(f"   ğŸ“‹ ç¤ºä¾‹: {urls[0][:60]}...")
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡")
                
        except Exception as e:
            print(f"   âŒ æœç´¢å¤±è´¥: {e}")
    
    # æ£€æŸ¥é…ç½®
    print(f"\nâš™ï¸ å½“å‰çˆ¬è™«é…ç½®:")
    print("-" * 40)
    
    sources = crawler.crawler_config.get('sources', [])
    enabled_sources = [s for s in sources if s.get('enabled')]
    
    print(f"å¯ç”¨çš„å›¾ç‰‡æº: {len(enabled_sources)} ä¸ª")
    for source in enabled_sources:
        print(f"  âœ… {source['name']}: {source.get('max_results', 0)} å¼  - {source.get('description', '')}")
    
    total_images = sum(s.get('max_results', 0) for s in enabled_sources)
    print(f"\nğŸ“Š é¢„æœŸæ¯ä½æ¼”å‘˜å›¾ç‰‡æ•°: {total_images} å¼ ")
    
    # éªŒè¯åªæœ‰TMDBå’Œç™¾åº¦
    expected_sources = {'tmdb_images', 'baidu_images'}
    actual_sources = {s['name'] for s in enabled_sources}
    
    if actual_sources == expected_sources:
        print("âœ… é…ç½®æ­£ç¡®: åªå¯ç”¨äº†TMDBå’Œç™¾åº¦å›¾ç‰‡")
    else:
        print(f"âš ï¸ é…ç½®å¼‚å¸¸: é¢„æœŸ {expected_sources}, å®é™… {actual_sources}")
    
    print(f"\nğŸ¯ å…³é”®è¯ä¼˜åŒ–:")
    print("  âœ… æ·»åŠ äº†'å•äºº'å…³é”®è¯")
    print("  âœ… æ·»åŠ äº†'ä¸ªäºº'å…³é”®è¯") 
    print("  âœ… æ·»åŠ äº†'ç‰¹å†™'å…³é”®è¯")
    print("  âœ… æ·»åŠ äº†'ç‹¬ç…§'å…³é”®è¯")
    print("  âœ… æ·»åŠ äº†ç™¾åº¦äººè„¸ç­›é€‰å‚æ•° (face=1)")


def main():
    """ä¸»å‡½æ•°"""
    try:
        test_clean_crawler()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ çˆ¬è™«æ¸…ç†å’Œä¼˜åŒ–å®Œæˆ!")
        print("\nğŸ“‹ æœ€ç»ˆé…ç½®:")
        print("  1. TMDBå®˜æ–¹å›¾ç‰‡: 10å¼ é«˜è´¨é‡å¤´åƒ")
        print("  2. ç™¾åº¦å‰§ç…§æœç´¢: 15å¼ å•äººå‰§ç…§")
        print("  3. æœç´¢å…³é”®è¯: ç”µå½±å+æ¼”å‘˜å+å•äºº+å‰§ç…§+ç‰¹å†™")
        print("  4. äººè„¸ç­›é€‰: å¯ç”¨ç™¾åº¦äººè„¸æ£€æµ‹å‚æ•°")
        print("  5. å®Œå…¨å…è´¹: æ— éœ€ä»»ä½•APIå¯†é’¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
